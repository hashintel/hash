---
authorPhoto: blog/8_sensitivity-assessor/ross-gore.png
postPhoto: blog/8_sensitivity-assessor/8_sensitivity-assessor-cover.jpg
title: "Sensitivity analysis within HASH simulations"
subtitle: "Identify conditions and variables that drive simulations towards unexpected outcomes"
author: "Ross Gore"
jobTitle: "Research Assistant Professor, VMASC"
date: "2022-09-16"
---

_This post is a guest contribution by Ross Gore, Research Assistant Professor at the Virginia Modeling, Analysis & Simulation Center (VMASC).

# Sensitivity analysis

Our story begins late at night wih a heroic researcher hard at work. Sat at their computer ahead of an important looming deadline, the researcher is busy analyzing the outcomes of various simulation runs. For some scenarios, the researcherâ€™s simulation produces outcomes which match their expectations, but for others the results diverge dramatically.

This sort of experience will be recognizable to anybody who has constructed an even remotely complex model of the real world before. Under circumstances where it is infeasible or impractical to study a system directly, researchers develop simulations using HASH to emulate a system's inner workings. When the outputs of these simulations fail to match experimental data, or prevailing expert opinions, researchers are faced with solving a challenging problem: **does the unexpected output reveal new knowledge about the system or is it due to a bug in code, incorrect data, or bad assumption?** Without the ability to easily conduct **sensitivity analyses**, making this determination requires checking source code, reviewing data integrity, and unpicking the logic that powers simulations.

Motivated by the high cost and labor intensive nature of identifying conditions and source code statements that drive a simulation towards an unexpected output we have developed the VMASC [Sensitivity Assessor](https://vmasc.shinyapps.io/SensitivityAssessor/), an online tool built to identify conditions and variables within HASH models that may consistently drive simulation runs towards unexpected outcomes.

In this post we'll explore how to take data generated directly from HASH simulations, convert that data into a form that is ingestible by the Sensitivity Assessor (using an [automated converter](https://vmasc.shinyapps.io/from-hash-to-sa/)), and then analyze the data using the Sensitivity Assessor. Both of these tools have been developed at the [Virginia Modeling, Analysis, and Simulation Center](https://vmasc.org/) of Old Dominion University by members of the Data Analytics Working Group. These tools are public facing and free to use.

# Making it real with an actual HASH simulation

Consider the following scenario using an actual HASH simulation of an epidemic. Within the simulation, agents are positioned randomly within the landscape. Some are initially ill; others are healthy but susceptible to illness. At each time step, agents move randomly throughout the simulated landscape. While moving randomly, if a healthy agent encounters an infected agent, the healthy agent becomes sick with a certain probability. When an agent becomes sick the agent is assigned a chance of recovery.  Every sick agent increments their accumulated sick time at the start of each new time step. Once the sick time exceeds the sickness duration value, the agent either (i) dies (based on their chance of recovery) or (ii) survives and becomes immune. Once an agent becomes immune, the immunity lasts only for a specified number of time steps. Once the immunity period for an agent is reached, the agent returns to a healthy state but remains susceptible to illness.

The following figures show the HASH simulation as it progresses. Green squares represent the healthy agents, red squares represent the sick agents, and white squares represent the immune agents. The first screenshot displays the start of the simulation immediately following the initialization of all agents. The second figure shows the simulation after fifteen time steps and the third figure displays the simulation state after thirty time steps.

<TalkSlide width="766" height="448" src="/blog/8_sensitivity-assessor/figure-1_simulation-init-state.png">

Figure 1: Start of the simulation immediately following initialization

</TalkSlide>

<TalkSlide width="768" height="436" src="/blog/8_sensitivity-assessor/figure-2_simulation-step-15.png">

Figure 2: The state of the simulation after 15 time steps

</TalkSlide>

<TalkSlide width="774" height="464" src="/blog/8_sensitivity-assessor/figure-2_simulation-step-15.png">

Figure 3: The state of the simulation after 30 time steps

</TalkSlide>

The simulation is meant to represent the spread of a virus and its effects on the population. However, there are times when the number of healthy agents within the simulation falls to zero depending on input values. Initially one may not anticipate that all agents in the simulation can become sick. This is an alarming outcome as it would imply that there are not any healthy people to provide healthcare or other essential services.

The following screen capture shows the graph of the infection process for one of the experiments that was created. It highlights a simulation run where the number of healthy agents falls to zero.

<TalkSlide width="958" height="450" src="/blog/8_sensitivity-assessor/figure-2_simulation-step-15.png">

Figure 4: A times series of the immune, infected and healthy agents for a simulation run.

</TalkSlide>
